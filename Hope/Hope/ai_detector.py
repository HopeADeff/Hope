#!/usr/bin/env python3
"""
AI Image Detection Module for Hope-AD
Detects whether an image was generated by AI using multiple methods.
"""

import sys
import io
import numpy as np
from PIL import Image, ImageFilter
from pathlib import Path
from typing import Tuple, Dict, Optional, List, Union
from dataclasses import dataclass
from enum import Enum

try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    from scipy import fftpack, stats
    from scipy.ndimage import sobel, laplace
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from utils import println, ensure_utf8_stdout
    from gpu_utils import get_device, is_cuda_available, get_gpu_manager
except ImportError:
    def println(s):
        print(s)
    def ensure_utf8_stdout():
        pass
    def get_device():
        return torch.device("cuda" if torch.cuda.is_available() else "cpu") if TORCH_AVAILABLE else None
    def is_cuda_available():
        return TORCH_AVAILABLE and torch.cuda.is_available()


class DetectionMethod(Enum):
    """Available AI detection methods."""
    STATISTICAL = "statistical"
    CNN = "cnn"
    DIRE = "dire"
    COMBINED = "combined"


@dataclass
class DetectionResult:
    """Result of AI detection analysis."""
    is_ai_generated: bool
    confidence: float  # 0.0 to 1.0
    method: str
    details: Dict[str, float]
    
    def __str__(self):
        status = "AI-Generated" if self.is_ai_generated else "Real/Human"
        return f"{status} ({self.confidence:.1%} confidence) - {self.method}"


class StatisticalAnalyzer:
    """
    Statistical analysis for AI detection.
    Analyzes noise patterns, frequency domain, and color histograms.
    """
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
    
    def analyze(self, image: Image.Image) -> Dict[str, float]:
        """
        Perform statistical analysis on an image.
        
        Args:
            image: PIL Image to analyze
            
        Returns:
            Dictionary of analysis scores
        """
        img_array = np.array(image.convert('RGB'), dtype=np.float32)
        
        results = {}
        
        results['noise_score'] = self._analyze_noise(img_array)
        
        if SCIPY_AVAILABLE:
            results['frequency_score'] = self._analyze_frequency(img_array)
        else:
            results['frequency_score'] = 0.5
        
        results['color_score'] = self._analyze_color_histogram(img_array)
        
        results['edge_score'] = self._analyze_edges(img_array)
        
        results['texture_score'] = self._analyze_texture(img_array)
        
        results['artifact_score'] = self._analyze_artifacts(img_array)
        
        return results
    
    def _analyze_noise(self, img_array: np.ndarray) -> float:
        """Analyze noise patterns (AI often has unnaturally smooth noise)."""
        gray = 0.299 * img_array[:,:,0] + 0.587 * img_array[:,:,1] + 0.114 * img_array[:,:,2]
        
        
        if SCIPY_AVAILABLE:
            from scipy.ndimage import uniform_filter
            mean = uniform_filter(gray, size=5)
            sqr_mean = uniform_filter(gray**2, size=5)
            variance = sqr_mean - mean**2
            
            variance_std = np.std(variance)
            variance_mean = np.mean(variance)
            
            if variance_mean > 0:
                uniformity = 1 - min(1, variance_std / variance_mean)
            else:
                uniformity = 0.5
        else:
            noise = gray - np.roll(gray, 1, axis=0)
            uniformity = 1 - min(1, np.std(noise) / 30)
        
        return uniformity
    
    def _analyze_frequency(self, img_array: np.ndarray) -> float:
        """Analyze frequency domain characteristics."""
        if not SCIPY_AVAILABLE:
            return 0.5
        
        gray = 0.299 * img_array[:,:,0] + 0.587 * img_array[:,:,1] + 0.114 * img_array[:,:,2]
        
        f_transform = fftpack.fft2(gray)
        f_shift = fftpack.fftshift(f_transform)
        magnitude = np.abs(f_shift)
        
        h, w = magnitude.shape
        center_h, center_w = h // 2, w // 2
        
        mask_size = min(h, w) // 4
        high_freq_mask = np.ones_like(magnitude, dtype=bool)
        high_freq_mask[center_h-mask_size:center_h+mask_size, 
                      center_w-mask_size:center_w+mask_size] = False
        
        high_freq_energy = np.sum(magnitude[high_freq_mask])
        total_energy = np.sum(magnitude)
        
        if total_energy > 0:
            high_freq_ratio = high_freq_energy / total_energy
            score = 1 - min(1, high_freq_ratio * 2)
        else:
            score = 0.5
        
        return score
    
    def _analyze_color_histogram(self, img_array: np.ndarray) -> float:
        """Analyze color histogram for unnatural distributions."""
        scores = []
        
        for channel in range(3):
            hist, _ = np.histogram(img_array[:,:,channel], bins=256, range=(0, 255))
            hist = hist / hist.sum()
            
            hist_nonzero = hist[hist > 0]
            entropy = -np.sum(hist_nonzero * np.log2(hist_nonzero))
            
            normalized_entropy = entropy / 8.0
            
            scores.append(1 - normalized_entropy)
        
        return np.mean(scores)
    
    def _analyze_edges(self, img_array: np.ndarray) -> float:
        """Analyze edge patterns."""
        gray = 0.299 * img_array[:,:,0] + 0.587 * img_array[:,:,1] + 0.114 * img_array[:,:,2]
        
        if SCIPY_AVAILABLE:
            edges_x = sobel(gray, axis=0)
            edges_y = sobel(gray, axis=1)
            edges = np.sqrt(edges_x**2 + edges_y**2)
            
            edge_std = np.std(edges)
            edge_mean = np.mean(edges)
            
            if edge_mean > 0:
                edge_sharpness = min(1, edge_std / edge_mean)
            else:
                edge_sharpness = 0.5
            
            return 1 - edge_sharpness
        else:
            dx = np.diff(gray, axis=1)
            dy = np.diff(gray, axis=0)
            gradient_mag = np.mean(np.abs(dx)) + np.mean(np.abs(dy))
            return 1 - min(1, gradient_mag / 50)
    
    def _analyze_texture(self, img_array: np.ndarray) -> float:
        """Analyze texture uniformity."""
        gray = 0.299 * img_array[:,:,0] + 0.587 * img_array[:,:,1] + 0.114 * img_array[:,:,2]
        
        patch_size = 32
        h, w = gray.shape
        
        variances = []
        for i in range(0, h - patch_size, patch_size):
            for j in range(0, w - patch_size, patch_size):
                patch = gray[i:i+patch_size, j:j+patch_size]
                variances.append(np.var(patch))
        
        if len(variances) > 1:
            variance_of_variances = np.var(variances)
            mean_variance = np.mean(variances)
            
            if mean_variance > 0:
                uniformity = 1 - min(1, variance_of_variances / (mean_variance ** 2))
            else:
                uniformity = 0.5
            
            return uniformity
        
        return 0.5
    
    def _analyze_artifacts(self, img_array: np.ndarray) -> float:
        """Analyze for typical AI artifacts."""
        gray = 0.299 * img_array[:,:,0] + 0.587 * img_array[:,:,1] + 0.114 * img_array[:,:,2]
        
        h, w = gray.shape
        
        scores = []
        for offset in [64, 128, 256]:
            if offset < h and offset < w:
                region1 = gray[:h-offset, :w-offset]
                region2 = gray[offset:, offset:]
                
                if region1.size > 0:
                    correlation = np.corrcoef(region1.flatten()[:10000], 
                                             region2.flatten()[:10000])[0, 1]
                    if not np.isnan(correlation):
                        scores.append(abs(correlation))
        
        if scores:
            return np.mean(scores)
        return 0.5
    
    def get_ai_probability(self, analysis: Dict[str, float]) -> float:
        """
        Calculate overall AI probability from analysis scores.
        
        Args:
            analysis: Dictionary of analysis scores
            
        Returns:
            Probability (0-1) that image is AI-generated
        """
        weights = {
            'noise_score': 0.20,
            'frequency_score': 0.25,
            'color_score': 0.15,
            'edge_score': 0.20,
            'texture_score': 0.15,
            'artifact_score': 0.05
        }
        
        weighted_sum = sum(
            analysis.get(key, 0.5) * weight 
            for key, weight in weights.items()
        )
        
        return weighted_sum


class CNNDetector:
    """
    CNN-based AI image detector.
    Uses a simple ResNet-style classifier.
    """
    
    def __init__(self, model_path: Optional[str] = None, verbose: bool = True):
        self.verbose = verbose
        self.model = None
        self.device = None
        
        if TORCH_AVAILABLE:
            self.device = get_device()
            self._build_model()
            
            if model_path and Path(model_path).exists():
                self._load_weights(model_path)
    
    def _build_model(self):
        """Build a simple CNN classifier."""
        if not TORCH_AVAILABLE:
            return
        
        class SimpleClassifier(nn.Module):
            def __init__(self):
                super().__init__()
                self.features = nn.Sequential(
                    nn.Conv2d(3, 32, 3, padding=1),
                    nn.BatchNorm2d(32),
                    nn.ReLU(),
                    nn.MaxPool2d(2),
                    
                    nn.Conv2d(32, 64, 3, padding=1),
                    nn.BatchNorm2d(64),
                    nn.ReLU(),
                    nn.MaxPool2d(2),
                    
                    nn.Conv2d(64, 128, 3, padding=1),
                    nn.BatchNorm2d(128),
                    nn.ReLU(),
                    nn.MaxPool2d(2),
                    
                    nn.Conv2d(128, 256, 3, padding=1),
                    nn.BatchNorm2d(256),
                    nn.ReLU(),
                    nn.AdaptiveAvgPool2d((4, 4))
                )
                
                self.classifier = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(256 * 4 * 4, 512),
                    nn.ReLU(),
                    nn.Dropout(0.5),
                    nn.Linear(512, 1),
                    nn.Sigmoid()
                )
            
            def forward(self, x):
                x = self.features(x)
                x = self.classifier(x)
                return x
        
        self.model = SimpleClassifier().to(self.device)
        self.model.eval()
    
    def _load_weights(self, path: str):
        """Load pre-trained weights."""
        if self.model is None:
            return
        
        try:
            state_dict = torch.load(path, map_location=self.device)
            self.model.load_state_dict(state_dict)
            if self.verbose:
                println(f"Loaded CNN weights from {path}")
        except Exception as e:
            if self.verbose:
                println(f"Warning: Could not load weights: {e}")
    
    def predict(self, image: Image.Image) -> float:
        """
        Predict if image is AI-generated.
        
        Args:
            image: PIL Image
            
        Returns:
            Probability (0-1) of being AI-generated
        """
        if not TORCH_AVAILABLE or self.model is None:
            return 0.5  # Unknown
        
        img = image.convert('RGB').resize((224, 224))
        img_array = np.array(img, dtype=np.float32) / 255.0
        
        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)
        img_tensor = img_tensor.to(self.device)
        
        with torch.no_grad():
            output = self.model(img_tensor)
            probability = output.item()
        
        return probability


class AIDetector:
    """
    Main AI Detection class combining multiple methods.
    """
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self.statistical_analyzer = StatisticalAnalyzer(verbose=False)
        self.cnn_detector = CNNDetector(verbose=False) if TORCH_AVAILABLE else None
    
    def detect(self, image: Union[str, Image.Image], 
               method: DetectionMethod = DetectionMethod.COMBINED,
               threshold: float = 0.5) -> DetectionResult:
        """
        Detect if an image is AI-generated.
        
        Args:
            image: Path to image or PIL Image
            method: Detection method to use
            threshold: Probability threshold for classification
            
        Returns:
            DetectionResult with analysis
        """
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        
        if self.verbose:
            println(f"Analyzing image ({image.size[0]}x{image.size[1]})...")
        
        details = {}
        
        if method in [DetectionMethod.STATISTICAL, DetectionMethod.COMBINED]:
            stat_analysis = self.statistical_analyzer.analyze(image)
            stat_prob = self.statistical_analyzer.get_ai_probability(stat_analysis)
            details['statistical'] = stat_prob
            details.update({f'stat_{k}': v for k, v in stat_analysis.items()})
        
        if method in [DetectionMethod.CNN, DetectionMethod.COMBINED]:
            if self.cnn_detector:
                cnn_prob = self.cnn_detector.predict(image)
                details['cnn'] = cnn_prob
            else:
                details['cnn'] = 0.5
        
        if method == DetectionMethod.COMBINED:
            probability = details.get('statistical', 0.5) * 0.6 + details.get('cnn', 0.5) * 0.4
        elif method == DetectionMethod.STATISTICAL:
            probability = details.get('statistical', 0.5)
        elif method == DetectionMethod.CNN:
            probability = details.get('cnn', 0.5)
        else:
            probability = 0.5
        
        is_ai = probability >= threshold
        
        result = DetectionResult(
            is_ai_generated=is_ai,
            confidence=probability,
            method=method.value,
            details=details
        )
        
        if self.verbose:
            println(f"Result: {result}")
        
        return result
    
    def batch_detect(self, image_paths: List[str], 
                     method: DetectionMethod = DetectionMethod.COMBINED) -> List[DetectionResult]:
        """Detect AI in multiple images."""
        results = []
        for path in image_paths:
            try:
                result = self.detect(path, method)
                results.append(result)
            except Exception as e:
                if self.verbose:
                    println(f"Error processing {path}: {e}")
                results.append(DetectionResult(
                    is_ai_generated=False,
                    confidence=0.0,
                    method="error",
                    details={"error": str(e)}
                ))
        return results


def detect_ai(image_path: str, verbose: bool = True) -> DetectionResult:
    """
    Convenience function to detect AI in an image.
    
    Args:
        image_path: Path to image
        verbose: Print status messages
        
    Returns:
        DetectionResult
    """
    detector = AIDetector(verbose=verbose)
    return detector.detect(image_path)


if __name__ == "__main__":
    ensure_utf8_stdout()
    
    if len(sys.argv) > 1:
        image_path = sys.argv[1]
        result = detect_ai(image_path)
        print(f"\nResult: {result}")
        print(f"\nDetails:")
        for key, value in result.details.items():
            print(f"  {key}: {value:.4f}")
    else:
        print("Usage: python ai_detector.py <image_path>")
        print("\nAI Detection Module")
        print("Methods: statistical, cnn, combined")
